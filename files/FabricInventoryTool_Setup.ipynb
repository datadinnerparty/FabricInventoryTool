{"cells":[{"cell_type":"code","source":["#import necessary libraries\n","import sempy.fabric as fabric\n","import pandas as pd\n","import numpy as np\n","import re\n","from notebookutils import mssparkutils\n","from datetime import date,datetime\n","\n","#import sempy_labs as labs\n","#from sempy_labs import directlake\n","#from sempy_labs.tom import connect_semantic_model\n","\n","###########################################################################################################\n","### Set Parameters\n","###########################################################################################################\n","#Define lakehouse and schema names\n","workspace_name = \"amaser_dp700\" #this is the workspace name where the notebook runs, and where the lakehouse lives\n","lakehouse_name = \"test_fit\" #this is the name of the lakehouse, in the event that it needs to becreated by this notebook\n","schema_name = \"fitschema\"  #This is the name of the schema.  If you want a schema-enabled lakehouse, you MUST create the lakehouse ahead of time, by hand\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"750da3d7-2893-40ef-96f1-7e833797ea30","normalized_state":"finished","queued_time":"2026-01-06T00:42:11.1216054Z","session_start_time":null,"execution_start_time":"2026-01-06T00:42:15.4203344Z","execution_finish_time":"2026-01-06T00:42:19.2794896Z","parent_msg_id":"c5b07bc4-c5d8-449c-8198-fda897ca52b4"},"text/plain":"StatementMeta(, 750da3d7-2893-40ef-96f1-7e833797ea30, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"aae0391e-9857-440c-9087-5ea7650f69f4"},{"cell_type":"code","source":["#set default values\n","lakehouse_description = \"Fabric Inventory Tool Lakehouse\"  # this is only used if the notebook creates a new lakehouse\n","full_lakehouse_name = f'{workspace_name}.{lakehouse_name}.{schema_name}'\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"750da3d7-2893-40ef-96f1-7e833797ea30","normalized_state":"finished","queued_time":"2026-01-06T00:42:11.1922531Z","session_start_time":null,"execution_start_time":"2026-01-06T00:42:19.2814244Z","execution_finish_time":"2026-01-06T00:42:19.6174247Z","parent_msg_id":"f2528b86-4fb7-48f4-bb24-080dc368584f"},"text/plain":"StatementMeta(, 750da3d7-2893-40ef-96f1-7e833797ea30, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e17a98d7-3a92-48b7-be66-01bae0bbd865"},{"cell_type":"code","source":["###################################################################################################\n","### DEFINE FUNCTIONS\n","###################################################################################################\n","def logActivity(table_name,message):\n","    logquery = f'INSERT INTO {full_lakehouse_name}.inventorylog (timeval,workspace_id,Message) VALUES (CURRENT_TIMESTAMP(),\"{table_name}\",\"{message}\")'\n","    #print(f'log query={logquery}')\n","    #print(logquery)\n","    spark.sql(logquery)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"750da3d7-2893-40ef-96f1-7e833797ea30","normalized_state":"finished","queued_time":"2026-01-06T00:42:11.2643156Z","session_start_time":null,"execution_start_time":"2026-01-06T00:42:19.6198885Z","execution_finish_time":"2026-01-06T00:42:19.9614421Z","parent_msg_id":"535646f6-4796-4576-9636-73cf0807c6cc"},"text/plain":"StatementMeta(, 750da3d7-2893-40ef-96f1-7e833797ea30, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3364dcb9-9a22-42c3-8566-dec82ac92f4d"},{"cell_type":"code","source":["\n","# check if lakehouse exists.  If not, create a lakehouse \n","try:\n","    lakehouse_object = mssparkutils.lakehouse.get(lakehouse_name)\n","    lakehouse_id=lakehouse_object.id\n","    print(\"Lakehouse exists\")\n","except Exception as e:\n","        print (\"Lakehouse does not exist.  Attempting to create lakehouse...\")\n","        try:\n","            fabric.create_lakehouse(display_name=lakehouse_name,description=lakehouse_description,workspace=workspace_name)\n","            lakehouse_object = mssparkutils.lakehouse.get(lakehouse_name)\n","            print(\"Lakehouse created without schema enabling\")\n","            lakehouse_id=lakehouse_object.id\n","            schema_name = \"dbo\"\n","        except Exception as e:\n","            print('Unable to create lakehouse')\n","            print(e)\n","    \n","#check if schema exists (if schema-enabled)\n","if schema_name == \"dbo\":\n","    print (\"Default schema.  No check performed\")\n","else:\n","    schema_sql  = f\"CREATE SCHEMA IF NOT EXISTS {workspace_name}.{lakehouse_name}.{schema_name}\"\n","    spark.sql(schema_sql)\n","    "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"750da3d7-2893-40ef-96f1-7e833797ea30","normalized_state":"finished","queued_time":"2026-01-06T00:42:11.4039641Z","session_start_time":null,"execution_start_time":"2026-01-06T00:42:19.9635583Z","execution_finish_time":"2026-01-06T00:42:29.9846865Z","parent_msg_id":"730cac04-5b37-406e-b20c-6384f17cb197"},"text/plain":"StatementMeta(, 750da3d7-2893-40ef-96f1-7e833797ea30, 6, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Lakehouse exists\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1face783-ad65-4283-b926-87a6e0f530bd"},{"cell_type":"code","source":["# create tables\n","#create the log table. \n","logquery = f'CREATE TABLE IF NOT EXISTS {full_lakehouse_name}.inventorylog (timeval TIMESTAMP, workspace_id STRING, Message STRING) USING DELTA'\n","#print(logquery)\n","spark.sql(logquery)\n","print(\"Log Table Created\")\n","workspacequery = f'CREATE TABLE IF NOT EXISTS {full_lakehouse_name}.workspaces (timeval DATE, workspace_name STRING,workspace_id STRING,is_read_only BOOLEAN, is_dedicated_capacity BOOLEAN, capacity_id STRING,type STRING)'\n","spark.sql(workspacequery)\n","print(\"Workspace Table created\")\n","itemsquery = f\"\"\"\n","    CREATE TABLE IF NOT EXISTS \n","    {full_lakehouse_name}.fabricitems (timeval DATE, item_name STRING, item_id STRING,Description STRING, item_type STRING, workspace_id STRING,workspace_name STRING)\n","    \"\"\"\n","spark.sql(itemsquery)\n","print(\"Items table created\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"750da3d7-2893-40ef-96f1-7e833797ea30","normalized_state":"finished","queued_time":"2026-01-06T00:42:11.4855051Z","session_start_time":null,"execution_start_time":"2026-01-06T00:42:29.9866729Z","execution_finish_time":"2026-01-06T00:42:34.931292Z","parent_msg_id":"d5b15be3-d3d1-4363-8b97-aea39b7d2ca1"},"text/plain":"StatementMeta(, 750da3d7-2893-40ef-96f1-7e833797ea30, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Log Table Created\nWorkspace Table created\nItems table created\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2764066e-1821-4732-ab14-7d9e8f18ffd4"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}